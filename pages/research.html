<!DOCTYPE html>
<html>

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>
        Robin Walters - Research
    </title>

    <!-- Bootstrap & MDB -->
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="stylesheet" href="../css/main.css">
    <link rel="canonical" href="/">

</head>

<body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>
        <!-- Nav Bar -->
        <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
            <div class="container">
                <!-- Logo -->
                <a href="../index.html" class="navbar-brand">
                    <img src="../images/logo.png" alt="Logo" style="height: 60px;"> <!-- Adjust the height as needed -->
                </a>
                <!-- Navbar Toggle -->
                <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar top-bar"></span>
                    <span class="icon-bar middle-bar"></span>
                    <span class="icon-bar bottom-bar"></span>
                </button>
                <div class="collapse navbar-collapse text-right" id="navbarNav">
                    <ul class="navbar-nav ml-auto flex-nowrap">
                        <!-- About -->
                        <li class="nav-item active">
                            <a class="nav-link" href="../index.html">
                                Home              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="research.html">
                                Research              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="geometric-learning-lab.html">
                                Lab             
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <li class="nav-item active">
                            <a class="nav-link" href="teaching.html">
                                Teaching              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li>

                        <!-- <li class="nav-item active">
                            <a class="nav-link" href="/">
                                Contact              
                                <span class="sr-only">(current)</span>              
                            </a>
                        </li> -->

                    </ul>
                </div>
            </div>
        </nav>

    </header>


    <!-- Content -->

    <div class="container mt-5">
        <div class="post">

            <header class="post-header">
                <h1 class="post-title-research-page">
                    <span class="font-weight-bold"><span style="color: red;">Research</span></span>
                </h1>
                <p class="desc"></p>
            </header>

            <article>

                <div class="clearfix">
                    <p>
                        Our research can be divided into several topic areas.
                    </p>
                    <p>
                        1. Theory of machine learning through the lens of symmetry including generalization and approximation error for equivariant neural networks, study of approximate and extrinsic symmetry in deep learning, symmetries of neural network parameters spaces and
                        their effects on optimization, structure of equivariant neural networks.
                    </p>
                    <p>
                        2. design of equivariant neural networks for scientific and engineering applications including fluid dynamics, radar signal processing, astrophysical simulation, radar signal processing, and materials and thin films.
                    </p>
                    <p>
                        3. Equivariant methods for deep reinforcement learning with an emphasis on robotic learning and perception. Our goal are sample efficient algorithms for real world robot learning.
                    </p>
                    <p>
                        4. Design models with can utilize approximate and unknown symmetry. These include symmetry discovery methods, relaxed equivariant methods, applications of equivariant models in cases of extrinsic symmetry, and methods which can learn group actions in
                        cases of latent symmetry.
                    </p>

                </div>

            </article>

            <article>

                <header class="post-header">
                    <h1 class="post-title-research-page">
                        <span class="font-weight-bold">Selected Publications</span>
                    </h1>
                    <p class="desc"></p>
                </header>

                <div class="publications">

                    <!-- Dian CoRL 2024 equidiff  -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2024</abbr>
                                    <img src="../publications/images/dian_corl24.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Diffusion Policy</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://www.linkedin.com/in/stephen-hart-3711666/" target="_blank" rel="noopener noreferrer">Stephen Hart</a>,
                                        <a href="https://www.linkedin.com/in/surovik/" target="_blank" rel="noopener noreferrer">David Surovik</a>,
                                        <a href="https://kelestemur.com/" target="_blank" rel="noopener noreferrer">Tarik Kelestemur</a>,
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://www.linkedin.com/in/haibo-zhao-b68742250/" target="_blank" rel="noopener noreferrer">Haibo Zhao</a>,
                                        <a href="https://www.linkedin.com/in/mark-yeatman-58a49763/" target="_blank" rel="noopener noreferrer">Mark Yeatman</a>,
                                        <a href="https://www.robo.guru/" target="_blank" rel="noopener noreferrer">Jiuguang Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2407.01812" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://equidiff.github.io/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                            Recent work has shown diffusion models are an effective approach to learning the multimodal distributions arising from demonstration data in behavior cloning. However, a drawback of this approach is the need to learn a denoising function, which is significantly more complex than learning an explicit policy. In this work, we propose Equivariant Diffusion Policy, a novel diffusion policy learning method that leverages domain symmetries to obtain better sample efficiency and generalization in the denoising function. We theoretically analyze the SO(2) symmetry of full 6-DoF control and characterize when a diffusion model is SO(2)-equivariant. We furthermore evaluate the method empirically on a set of 12 simulation tasks in MimicGen, and show that it obtains a success rate that is, on average, 21.9% higher than the baseline Diffusion Policy. We also evaluate the method on a real-world system to show that effective policies can be learned with relatively few training samples, whereas the baseline Diffusion Policy cannot.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">TMLR 2024</abbr>
                                    <img src="../publications/images/combination-homomorphic-emg.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Fast and Expressive Gesture Recognition using a Combination-Homomorphic Electromyogram Encoder</div>
                                    <div class="author">
                                        <a href="https://nik-sm.github.io/" target="_blank" rel="noopener noreferrer">Niklas Smedemark-Margulies*</a>,
                                        <a href="https://www.linkedin.com/in/yunusbicer/" target="_blank" rel="noopener noreferrer">Yunus Bicer*</a>,
                                        <a href="https://www.linkedin.com/in/elifnursunger/" target="_blank" rel="noopener noreferrer">Elifnur Sunger</a>,
                                        <a href="https://coe.northeastern.edu/people/imbiriba-tales/" target="_blank" rel="noopener noreferrer">Tales Imbiriba</a>,
                                        <a href="https://bouve.northeastern.edu/directory/eugene-tunik/" target="_blank" rel="noopener noreferrer">Eugene Tunik</a>,
                                        <a href="https://web.northeastern.edu/deniz/" target="_blank" rel="noopener noreferrer">Deniz Erdogmus</a>,
                                        <a href="https://coe.northeastern.edu/people/yarossi-mathew/" target="_blank" rel="noopener noreferrer">Mathew Yarossi</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Transactions on Machine Learning Research</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/pdf?id=j5T4pcLbcY" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/nik-sm/com-hom-emg" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                        We study the task of gesture recognition from electromyography (EMG), with the goal of enabling expressive human-computer interaction at high accuracy, while minimizing the time required for new subjects to provide calibration data.
                                        To fulfill these goals, we define combination gestures consisting of a direction component and a modifier component.
                                        New subjects only demonstrate the single component gestures and we seek to extrapolate from these to all possible single or combination gestures.
                                        We extrapolate to unseen combination gestures by combining the feature vectors of real single gestures to produce synthetic training data.
                                        This strategy allows us to provide a large and flexible gesture vocabulary, while not requiring new subjects to demonstrate combinatorially many example gestures.
                                        We pre-train an encoder and a combination operator using self-supervision, so that we can produce useful synthetic training data for unseen test subjects. 
                                        To evaluate the proposed method, we collect and release a real-world EMG dataset, and measure the effect of augmented supervision against two baselines: a partially-supervised model trained with only single gesture data from the unseen subject, and a fully-supervised model trained with real single and real combination gesture data from the unseen subject.
                                        We find that the proposed method provides a dramatic improvement over the partially-supervised model, and achieves a useful classification accuracy that in some cases approaches the performance of the fully-supervised model.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>
                    
                    <!-- haojie FourTran icrl 2024 -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2024</abbr>
                                    <img src="../publications/images/iclr_foutran.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://owenhowell20.github.io/" target="_blank" rel="noopener noreferrer">Owen Howell*</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu*</a>,
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt**</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters**</a>
                                    </div>

                                    <div class="periodical">
                                        <em>The International Conference on Learning Representations 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://openreview.net/forum?id=UulwvAU1W0" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://haojhuang.github.io/fourtran_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <!-- <a href="https://zenodo.org/records/10359729" class="btn btn-sm z-depth-0" role="button">Dataset</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>


                    <!-- Haojie IJRR 2024 Leverage symmetries in pick and place  -->
                    <h2 class="year">2024</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">IJRR 2024</abbr>
                                    <img src="../publications/images/ijrr_lspp.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Leveraging Symmetries in Pick and Place</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io/" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://www.linkedin.com/in/arsh-tangri-a71194195/" target="_blank" rel="noopener noreferrer">Arsh Tangri</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>
                                        <a href="https://helpinghandslab.netlify.app/people/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>,
                                    </div>

                                    <div class="periodical">
                                        <em>The International Journal of Robotics Research, Volume 43, Issue 4, 2024</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2308.07948" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://haojhuang.github.io/etp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                        <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>
                    

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/hermes.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Modeling Dynamics over Meshes with Gauge Equivariant Nonlinear Message Passing</div>
                                    <div class="author">
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://www.khoury.northeastern.edu/home/lsw/" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Neural Information Processing Systems 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2310.19589" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/jypark0/hermes" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://jypark0.github.io/hermes/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Data over non-Euclidean manifolds, often discretized as surface meshes, naturally arise in computer graphics and biological and physical systems. In particular, solutions to partial differential equations (PDEs) over manifolds depend critically on the underlying geometry. While graph neural networks have been successfully applied to PDEs, they do not incorporate surface geometry and do not consider local gauge symmetries of the manifold. Alternatively, recent works on gauge equivariant convolutional and attentional architectures on meshes leverage the underlying geometry but underperform in modeling surface PDEs with complex nonlinear dynamics. To address these issues, we introduce a new gauge equivariant architecture using nonlinear message passing. Our novel architecture achieves higher performance than either convolutional or attentional networks on domains with highly complex and nonlinear dynamics. However, similar to the non-mesh case, design trade-offs favor convolutional, attentional, or message passing networks for different tasks; we investigate in which circumstances our message passing method provides the most benefit.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">NeurIPS 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/dian_neurips23.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">A General Theory of Correct, Incorrect, and Extrinsic Equivariance</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://zxp-s-works.github.io" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://xxs90.github.io/" target="_blank" rel="noopener noreferrer">Guanang Su</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Neural Information Processing Systems 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2303.04745.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/ext_theory" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Although equivariant machine learning has proven effective at many tasks, success depends heavily on the assumption that the ground truth function is symmetric over the entire domain matching the symmetry in an equivariant neural network. A missing piece in the equivariant learning literature is the analysis of equivariant networks when symmetry exists only partially in the domain. In this work, we present a general theory for such a situation. We propose pointwise definitions of correct, incorrect, and extrinsic equivariance, which allow us to quantify continu- ously the degree of each type of equivariance a function displays. We then study the impact of various degrees of incorrect or extrinsic symmetry on model error. We prove error lower bounds for invariant or equivariant networks in classification or regression settings with partially incorrect symmetry. We also analyze the poten- tially harmful effects of extrinsic equivariance. Experiments validate these results in three different environments.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICLR 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/surprising-effectiveness.gif" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="#" target="_blank" rel="noopener noreferrer">Neel Sortur</a>,
                                        <a href="#" target="_blank" rel="noopener noreferrer">Lawson L.S. Wong</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters*</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt*</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.09231.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://pointw.github.io/extrinsic_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications
                                            typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which
                                            cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover,
                                            surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect
                                            symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model
                                            can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICRA 2023</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/seil.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SEIL: Simulation-augmented Equivariant Imitation Learning</div>
                                    <div class="author">
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia*</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang*</a>,
                                        <a href="https://xxs90.github.io/" target="_blank" rel="noopener noreferrer">Guanang Su</a>,
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David Klee</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Robotics and Automation 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00194.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://saulbatman.github.io/project/seil/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: In robotic manipulation, acquiring samples is extremely expensive because it often requires interacting with the real world. Traditional image-level data augmentation has shown the potential to improve
                                            sample efficiency in various machine learning tasks. However, image-level data augmentation is insufficient for an imitation learning agent to learn good manipulation policies in a reasonable amount of demonstrations.
                                            We propose Simulation-augmented Equivariant Imitation Learning (SEIL), a method that combines a novel data augmentation strategy of supplementing expert trajectories with simulated transitions and an equivariant
                                            model that exploits the O(2) symmetry in robotic manipulation. Experimental evaluations demonstrate that our method can learn non-trivial manipulation tasks within ten demonstrations and outperforms the baselines
                                            with a significant margin.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2023</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICRA 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Edge-grasp-networks.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Edge Grasp Network: Graph-Based SE(3)-invariant Approach to Grasp Detection</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupend Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Robotics and Automation 2023</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2211.00191.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://haojhuang.github.io/edge_grasp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical
                                            applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input
                                            and works well with single-view point clouds observed from arbitrary viewing directions.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">ICML 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/sen.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Learning Symmetric Embedding Networks for Equivariant World Models</div>
                                    <div class="author">
                                        <a href="https://jypark0.github.io/" target="_blank" rel="noopener noreferrer">Jung Yeon Park</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://lfzhao.com/" target="_blank" rel="noopener noreferrer">Linfeng Zhao</a>,
                                        <a href="https://jwvdm.github.io/" target="_blank" rel="noopener noreferrer">Jan-Willem van de Meent</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We propose learning symmetric embedding networks (SENs) for input spaces where we do not know the effects of symmetry transformations, to a feature space where the transformation is known. This network can be combined with downstream task-specific equivariant networks and trained end-to-end in latent space. SENs can extend the applicability of equivariant networks to a wider variety of domains.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2204.11371" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <!-- <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a> -->
                                        <a href="https://github.com/jypark0/sen" class="btn btn-sm z-depth-0" role="button">Code</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Incorporating symmetries can lead to highly data-efficient and generalizable models by defining equivalence classes of data samples related by transformations. However, characterizing how transformations
                                            act on input data is often difficult, limiting the applicability of equivariant models. We propose learning symmetric embedding networks (SENs) that encode an input space (e.g. images), where we do not know
                                            the effect of transformations (e.g. rotations), to a feature space that transforms in a known manner under these operations. This network can be trained end-to-end with an equivariant task network to learn an
                                            explicitly symmetric representation. We validate this approach in the context of equivariant transition models with 3 distinct forms of symmetry. Our experiments demonstrate that SENs facilitate the application
                                            of equivariant networks to data with complex symmetry representations. Moreover, doing so can yield improvements in accuracy and generalization relative to both fully-equivariant and non-equivariant baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">PMLR Vol. 197</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/image-to-icosahedral.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Image to Icosahedral Projection for SO(3) Object Reasoning from Single-View Images</div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="https://sites.google.com/view/obiza" target="_blank" rel="noopener noreferrer">Ondrej Biza</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>
                                    </div>

                                    <div class="periodical">
                                        <em>We develop a hybrid equivariant model that incorporates SO(2) and SO(3) equivariant convolution layers to improve 3D reasoning from 2D images.   Our method outperforms baselines on shape classification and pose prediction tasks, especially in the low-data regime.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/abs/2207.08925" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/dmklee/image2icosahedral" target="_blank" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reasoning about 3D objects based on 2D images is challenging due to variations in appearance caused by viewing the object from different orientations. Tasks such as object classification are invariant
                                            to 3D rotations and other such as pose estimation are equivariant. However, imposing equivariance as a model constraint is typically not possible with 2D image input because we do not have an a priori model
                                            of how the image changes under out-of-plane object rotations. The only SO(3)-equivariant models that currently exist require point cloud or voxel input rather than 2D images. In this paper, we propose a novel
                                            architecture based on icosahedral group convolutions that reasons in SO(3) by learning a projection of the input image onto an icosahedron. The resulting model is approximately equivariant to rotation in SO(3).
                                            We apply this model to object pose estimation and shape classification tasks and find that it outperforms reasonable baselines.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RLDM 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr>
                                    <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/understanding-the-mechanisms.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Understanding the Mechanism behind Data Augmentation's Success on Image-based RL
                                    </div>
                                    <div class="author">
                                        <a href="https://dmklee.github.io/" target="_blank" rel="noopener noreferrer">David M. Klee</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Data augmentation is known to provide substantial benefits for image-based reinforcement learning (RL) but the mechanism is not clear.  We show that data augmentation increases both the equivariance and invariance of the convolutional encoder, e.g. the feature map is spatially smooth.  We show that a simple Gaussian blur operation can achieve the same effect for some of the tested environments.</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/paper.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://dmklee.github.io/assets/publications/data_aug/poster.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">Poster</a>
                                        <!-- <a href="https://dmklee.github.io/image2icosahedral/" target="_blank" class="btn btn-sm z-depth-0" role="button">Webpage</a> -->
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Reinforcement learning for continuous control tasks is challenging with image observations, due to the representation learning problem. A series of recent work has shown that augmenting the observations
                                            via random shifts during training significantly improves performance, even matching state-based methods. However, it is not well-understood why augmentation is so beneficial; since the method uses a nearly-shift
                                            equivariant convolutional encoder, shifting the input should have little impact on what features are learned. In this work, we investigate why random shifts are useful augmentations for image-based RL and show
                                            that it increases both the shift-equivariance and shift-invariance of the encoder. In other words, the visual features learned exhibit spatial continuity, which we show can be partially achieved using dropout.
                                            We hypothesize that the spatial continuity of the visual encoding simplifies learning for the subsequent linear layers in the actor-critic networks.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <!-- <abbr class="badge">ICML</abbr> -->
                                    <abbr class="badge">ICLR 2022</abbr>
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/SO(2)-Equivariant-Reinforcement-Learning.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">SO(2)-Equivariant Reinforcement Learning</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>International Conference on Learning Representations 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04439.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_rl_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Equivariant neural networks enforce symmetry within the structure of their convolutional layers, resulting in a substantial improvement in sample efficiency when learning an equivariant or invariant function.
                                            Such models are applicable to robotic manipulation learning which can often be formulated as a rotationally symmetric problem. This paper studies equivariant model architectures in the context of Q-learning
                                            and actor-critic reinforcement learning. We identify equivariant and invariant characteristics of the optimal Q-function and the optimal policy and propose equivariant DQN and SAC algorithms that leverage this
                                            structure. We present experiments that demonstrate that our equivariant versions of DQN and SAC can be significantly more sample efficient than competing algorithms on an important class of robotic manipulation
                                            problems.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">RSS 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/equi_transporter.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Transporter Network</div>
                                    <div class="author">
                                        <a href="https://haojhuang.github.io/" target="_blank" rel="noopener noreferrer">Haojie Huang</a>,
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Robotics: Science and Systems 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2202.09400.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/HaojHuang/Equivariant-Transporter-Net" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://haojhuang.github.io/etp_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Transporter Net is a recently proposed framework for pick and place that is able to learn good manipulation policies from a very few expert demonstrations [35]. A key reason why Transporter Net is so sample
                                            efficient is that the model incorporates rotational equivariance into the pick-conditioned place module, i.e. the model immediately generalizes learned pick-place knowledge to objects presented in different
                                            pick orientations. This paper proposes a novel version of Transporter Net that is equivariant to both pick and place orientation. As a result, our model immediately generalizes pick-place knowledge to different
                                            place orientations in addition to generalizing the pick orientation as before. Ultimately, our new model is more sample efficient and achieves better pick and place success rates than the baseline Transporter
                                            Net model.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2022</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2022</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/On-Robot-Learning-With-Equivariant-Models.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">On-Robot Learning With Equivariant Models</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="https://saulbatman.github.io/" target="_blank" rel="noopener noreferrer">Mingxi Jia</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2022</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2203.04923.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_rl" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_robot_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, equivariant neural network models have been shown to improve sample efficiency for tasks in computer vision and reinforcement learning. This paper explores this idea in the context of on-robot
                                            policy learning in which a policy must be learned entirely on a physical robotic system without reference to a model, a simulator, or an offline dataset. We focus on applications of Equivariant SAC to robotic
                                            manipulation and explore a number of variations of the algorithm. Ultimately, we demonstrate the ability to learn several non-trivial manipulation tasks completely through on-robot experiences in less than an
                                            hour or two of wall clock time.
                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

                    <h2 class="year">2021</h2>
                    <ol class="bibliography">
                        <li>
                            <div class="row">
                                <div class="col-sm-3 abbr">
                                    <abbr class="badge">CoRL 2021</abbr>
                                    <!-- <abbr class="badge">ICLR</abbr> -->
                                    <!-- <abbr class="badge">NeurIPS</abbr> <br/><br/> -->
                                    <img src="../publications/images/Equivariant-Q-Learning-in-Spatial-Action-Spaces.png" alt="Project Image" style="object-fit: contain;">
                                </div>

                                <div id="iClarify" class="col-sm-8">
                                    <div class="title">Equivariant Q Learning in Spatial Action Spaces</div>
                                    <div class="author">
                                        <a href="https://pointw.github.io" target="_blank" rel="noopener noreferrer">Dian Wang</a>,
                                        <a href="../index.html" target="_blank" rel="noopener noreferrer">Robin Walters</a>,
                                        <a href="https://zxp-s-works.github.io/" target="_blank" rel="noopener noreferrer">Xupeng Zhu</a>,
                                        <a href="https://www.khoury.northeastern.edu/people/robert-platt/" target="_blank" rel="noopener noreferrer">Robert Platt</a>
                                    </div>

                                    <div class="periodical">
                                        <em>Conference on Robot Learning 2021</em>
                                    </div>


                                    <div class="links">
                                        <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a>
                                        <a href="https://arxiv.org/pdf/2110.15443.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
                                        <a href="https://github.com/pointW/equi_q_corl21" class="btn btn-sm z-depth-0" role="button">Code</a>
                                        <a href="https://pointw.github.io/equi_q_page/" class="btn btn-sm z-depth-0" role="button">Webpage</a>
                                    </div>

                                    <!-- Hidden abstract block -->
                                    <div class="abstract hidden">
                                        <p>Abstract: Recently, a variety of new equivariant neural network model architectures have been proposed that generalize better over rotational and reflectional symmetries than standard models. These models are relevant
                                            to robotics because many robotics problems can be expressed in a rotationally symmetric way. This paper focuses on equivariance over a visual state space and a spatial action space - the setting where the robot
                                            action space includes a subset of SE(2). In this situation, we know a priori that rotations and translations in the state image should result in the same rotations and translations in the spatial action dimensions
                                            of the optimal policy. Therefore, we can use equivariant model architectures to make Q learning more sample efficient. This paper identifies when the optimal Q function is equivariant and proposes Q network
                                            architectures for this setting. We show experimentally that this approach outperforms standard methods in a set of challenging manipulation problems.

                                        </p>
                                    </div>
                                    <!-- Hidden bibtex block -->

                                </div>
                            </div>
                        </li>
                    </ol>

            </article>

            </div>

        </div>

        <!-- Footer -->


        <footer class="sticky-bottom mt-5 ">
            <div class="container ">
                Made with <a href="http://jekyllrb.com/ " target="_blank " rel="noopener noreferrer ">Jekyll</a> and Bootstrap.
            </div>
        </footer>

</body>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

<!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>

<!-- Enable Tooltips -->
<script type="text/javascript">
    $(function() {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>

<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

<!-- MathJax -->
<script type="text/javascript">
    window.MathJax = {
        tex: {
            tags: 'ams'
        }
    };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-185703812-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-185703812-1');
</script>

<script>
    $(document).ready(function() {
        $('a.abstract').click(function() {
            $(this).parent().parent().find(".abstract.hidden").toggleClass('open');
        });
        $('a.bibtex').click(function() {
            $(this).parent().parent().find(".bibtex.hidden").toggleClass('open');
        });
        $('.navbar-nav').find('a').removeClass('waves-effect waves-light');
    });
</script>

</html>
